{"cells":[{"cell_type":"code","execution_count":27,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2023-10-18T16:19:00.961517Z","iopub.status.busy":"2023-10-18T16:19:00.961112Z","iopub.status.idle":"2023-10-18T16:19:00.977110Z","shell.execute_reply":"2023-10-18T16:19:00.975750Z","shell.execute_reply.started":"2023-10-18T16:19:00.961490Z"},"trusted":true},"outputs":[],"source":["import os\n","from pathlib import Path\n","import pandas as pd\n","from sklearn.model_selection import train_test_split\n","from sklearn.linear_model import LinearRegression\n","from sklearn.metrics import mean_absolute_error\n","\n","for dirname, _, filenames in os.walk('/kaggle/input'):\n","    for filename in filenames:\n","        print(os.path.join(dirname, filename))\n","        paths = os.path.join(dirname, filename)"]},{"cell_type":"code","execution_count":28,"metadata":{"execution":{"iopub.execute_input":"2023-10-18T16:19:00.979825Z","iopub.status.busy":"2023-10-18T16:19:00.979460Z","iopub.status.idle":"2023-10-18T16:19:01.002239Z","shell.execute_reply":"2023-10-18T16:19:01.001100Z","shell.execute_reply.started":"2023-10-18T16:19:00.979798Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["<class 'pandas.core.frame.DataFrame'>\n","RangeIndex: 395 entries, 0 to 394\n","Data columns (total 33 columns):\n"," #   Column      Non-Null Count  Dtype \n","---  ------      --------------  ----- \n"," 0   school      395 non-null    object\n"," 1   sex         395 non-null    object\n"," 2   age         395 non-null    int64 \n"," 3   address     395 non-null    object\n"," 4   famsize     395 non-null    object\n"," 5   Pstatus     395 non-null    object\n"," 6   Medu        395 non-null    int64 \n"," 7   Fedu        395 non-null    int64 \n"," 8   Mjob        395 non-null    object\n"," 9   Fjob        395 non-null    object\n"," 10  reason      395 non-null    object\n"," 11  guardian    395 non-null    object\n"," 12  traveltime  395 non-null    int64 \n"," 13  studytime   395 non-null    int64 \n"," 14  failures    395 non-null    int64 \n"," 15  schoolsup   395 non-null    object\n"," 16  famsup      395 non-null    object\n"," 17  paid        395 non-null    object\n"," 18  activities  395 non-null    object\n"," 19  nursery     395 non-null    object\n"," 20  higher      395 non-null    object\n"," 21  internet    395 non-null    object\n"," 22  romantic    395 non-null    object\n"," 23  famrel      395 non-null    int64 \n"," 24  freetime    395 non-null    int64 \n"," 25  goout       395 non-null    int64 \n"," 26  Dalc        395 non-null    int64 \n"," 27  Walc        395 non-null    int64 \n"," 28  health      395 non-null    int64 \n"," 29  absences    395 non-null    int64 \n"," 30  G1          395 non-null    int64 \n"," 31  G2          395 non-null    int64 \n"," 32  G3          395 non-null    int64 \n","dtypes: int64(16), object(17)\n","memory usage: 102.0+ KB\n"]}],"source":["\n","path = \"https://raw.githubusercontent.com/ResidenciaTICBrisa/06_AcompanhamentoEnsinoMedio/develop/src/ML/student_data.csv\"\n","\n","df = pd.read_csv(path)\n","\n","df.info()"]},{"cell_type":"code","execution_count":29,"metadata":{"execution":{"iopub.execute_input":"2023-10-18T16:19:01.005366Z","iopub.status.busy":"2023-10-18T16:19:01.003728Z","iopub.status.idle":"2023-10-18T16:19:01.031231Z","shell.execute_reply":"2023-10-18T16:19:01.029867Z","shell.execute_reply.started":"2023-10-18T16:19:01.005327Z"},"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>school</th>\n","      <th>sex</th>\n","      <th>age</th>\n","      <th>address</th>\n","      <th>famsize</th>\n","      <th>Pstatus</th>\n","      <th>Medu</th>\n","      <th>Fedu</th>\n","      <th>Mjob</th>\n","      <th>Fjob</th>\n","      <th>...</th>\n","      <th>famrel</th>\n","      <th>freetime</th>\n","      <th>goout</th>\n","      <th>Dalc</th>\n","      <th>Walc</th>\n","      <th>health</th>\n","      <th>absences</th>\n","      <th>G1</th>\n","      <th>G2</th>\n","      <th>G3</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>GP</td>\n","      <td>F</td>\n","      <td>18</td>\n","      <td>U</td>\n","      <td>GT3</td>\n","      <td>A</td>\n","      <td>4</td>\n","      <td>4</td>\n","      <td>at_home</td>\n","      <td>teacher</td>\n","      <td>...</td>\n","      <td>4</td>\n","      <td>3</td>\n","      <td>4</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>3</td>\n","      <td>6</td>\n","      <td>5</td>\n","      <td>6</td>\n","      <td>6</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>GP</td>\n","      <td>F</td>\n","      <td>17</td>\n","      <td>U</td>\n","      <td>GT3</td>\n","      <td>T</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>at_home</td>\n","      <td>other</td>\n","      <td>...</td>\n","      <td>5</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>3</td>\n","      <td>4</td>\n","      <td>5</td>\n","      <td>5</td>\n","      <td>6</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>GP</td>\n","      <td>F</td>\n","      <td>15</td>\n","      <td>U</td>\n","      <td>LE3</td>\n","      <td>T</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>at_home</td>\n","      <td>other</td>\n","      <td>...</td>\n","      <td>4</td>\n","      <td>3</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>10</td>\n","      <td>7</td>\n","      <td>8</td>\n","      <td>10</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>GP</td>\n","      <td>F</td>\n","      <td>15</td>\n","      <td>U</td>\n","      <td>GT3</td>\n","      <td>T</td>\n","      <td>4</td>\n","      <td>2</td>\n","      <td>health</td>\n","      <td>services</td>\n","      <td>...</td>\n","      <td>3</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>5</td>\n","      <td>2</td>\n","      <td>15</td>\n","      <td>14</td>\n","      <td>15</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>GP</td>\n","      <td>F</td>\n","      <td>16</td>\n","      <td>U</td>\n","      <td>GT3</td>\n","      <td>T</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>other</td>\n","      <td>other</td>\n","      <td>...</td>\n","      <td>4</td>\n","      <td>3</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>5</td>\n","      <td>4</td>\n","      <td>6</td>\n","      <td>10</td>\n","      <td>10</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>390</th>\n","      <td>MS</td>\n","      <td>M</td>\n","      <td>20</td>\n","      <td>U</td>\n","      <td>LE3</td>\n","      <td>A</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>services</td>\n","      <td>services</td>\n","      <td>...</td>\n","      <td>5</td>\n","      <td>5</td>\n","      <td>4</td>\n","      <td>4</td>\n","      <td>5</td>\n","      <td>4</td>\n","      <td>11</td>\n","      <td>9</td>\n","      <td>9</td>\n","      <td>9</td>\n","    </tr>\n","    <tr>\n","      <th>391</th>\n","      <td>MS</td>\n","      <td>M</td>\n","      <td>17</td>\n","      <td>U</td>\n","      <td>LE3</td>\n","      <td>T</td>\n","      <td>3</td>\n","      <td>1</td>\n","      <td>services</td>\n","      <td>services</td>\n","      <td>...</td>\n","      <td>2</td>\n","      <td>4</td>\n","      <td>5</td>\n","      <td>3</td>\n","      <td>4</td>\n","      <td>2</td>\n","      <td>3</td>\n","      <td>14</td>\n","      <td>16</td>\n","      <td>16</td>\n","    </tr>\n","    <tr>\n","      <th>392</th>\n","      <td>MS</td>\n","      <td>M</td>\n","      <td>21</td>\n","      <td>R</td>\n","      <td>GT3</td>\n","      <td>T</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>other</td>\n","      <td>other</td>\n","      <td>...</td>\n","      <td>5</td>\n","      <td>5</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>10</td>\n","      <td>8</td>\n","      <td>7</td>\n","    </tr>\n","    <tr>\n","      <th>393</th>\n","      <td>MS</td>\n","      <td>M</td>\n","      <td>18</td>\n","      <td>R</td>\n","      <td>LE3</td>\n","      <td>T</td>\n","      <td>3</td>\n","      <td>2</td>\n","      <td>services</td>\n","      <td>other</td>\n","      <td>...</td>\n","      <td>4</td>\n","      <td>4</td>\n","      <td>1</td>\n","      <td>3</td>\n","      <td>4</td>\n","      <td>5</td>\n","      <td>0</td>\n","      <td>11</td>\n","      <td>12</td>\n","      <td>10</td>\n","    </tr>\n","    <tr>\n","      <th>394</th>\n","      <td>MS</td>\n","      <td>M</td>\n","      <td>19</td>\n","      <td>U</td>\n","      <td>LE3</td>\n","      <td>T</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>other</td>\n","      <td>at_home</td>\n","      <td>...</td>\n","      <td>3</td>\n","      <td>2</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>5</td>\n","      <td>5</td>\n","      <td>8</td>\n","      <td>9</td>\n","      <td>9</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>395 rows × 33 columns</p>\n","</div>"],"text/plain":["    school sex  age address famsize Pstatus  Medu  Fedu      Mjob      Fjob  \\\n","0       GP   F   18       U     GT3       A     4     4   at_home   teacher   \n","1       GP   F   17       U     GT3       T     1     1   at_home     other   \n","2       GP   F   15       U     LE3       T     1     1   at_home     other   \n","3       GP   F   15       U     GT3       T     4     2    health  services   \n","4       GP   F   16       U     GT3       T     3     3     other     other   \n","..     ...  ..  ...     ...     ...     ...   ...   ...       ...       ...   \n","390     MS   M   20       U     LE3       A     2     2  services  services   \n","391     MS   M   17       U     LE3       T     3     1  services  services   \n","392     MS   M   21       R     GT3       T     1     1     other     other   \n","393     MS   M   18       R     LE3       T     3     2  services     other   \n","394     MS   M   19       U     LE3       T     1     1     other   at_home   \n","\n","     ... famrel freetime  goout  Dalc  Walc health absences  G1  G2  G3  \n","0    ...      4        3      4     1     1      3        6   5   6   6  \n","1    ...      5        3      3     1     1      3        4   5   5   6  \n","2    ...      4        3      2     2     3      3       10   7   8  10  \n","3    ...      3        2      2     1     1      5        2  15  14  15  \n","4    ...      4        3      2     1     2      5        4   6  10  10  \n","..   ...    ...      ...    ...   ...   ...    ...      ...  ..  ..  ..  \n","390  ...      5        5      4     4     5      4       11   9   9   9  \n","391  ...      2        4      5     3     4      2        3  14  16  16  \n","392  ...      5        5      3     3     3      3        3  10   8   7  \n","393  ...      4        4      1     3     4      5        0  11  12  10  \n","394  ...      3        2      3     3     3      5        5   8   9   9  \n","\n","[395 rows x 33 columns]"]},"metadata":{},"output_type":"display_data"}],"source":["display(df)"]},{"cell_type":"code","execution_count":30,"metadata":{"execution":{"iopub.execute_input":"2023-10-18T16:19:01.036022Z","iopub.status.busy":"2023-10-18T16:19:01.035448Z","iopub.status.idle":"2023-10-18T16:19:01.057047Z","shell.execute_reply":"2023-10-18T16:19:01.055442Z","shell.execute_reply.started":"2023-10-18T16:19:01.035955Z"},"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>school</th>\n","      <th>sex</th>\n","      <th>age</th>\n","      <th>studytime</th>\n","      <th>failures</th>\n","      <th>higher</th>\n","      <th>internet</th>\n","      <th>absences</th>\n","      <th>G1</th>\n","      <th>G2</th>\n","      <th>G3</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>GP</td>\n","      <td>F</td>\n","      <td>18</td>\n","      <td>2</td>\n","      <td>0</td>\n","      <td>yes</td>\n","      <td>no</td>\n","      <td>6</td>\n","      <td>5</td>\n","      <td>6</td>\n","      <td>6</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>GP</td>\n","      <td>F</td>\n","      <td>17</td>\n","      <td>2</td>\n","      <td>0</td>\n","      <td>yes</td>\n","      <td>yes</td>\n","      <td>4</td>\n","      <td>5</td>\n","      <td>5</td>\n","      <td>6</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>GP</td>\n","      <td>F</td>\n","      <td>15</td>\n","      <td>2</td>\n","      <td>3</td>\n","      <td>yes</td>\n","      <td>yes</td>\n","      <td>10</td>\n","      <td>7</td>\n","      <td>8</td>\n","      <td>10</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>GP</td>\n","      <td>F</td>\n","      <td>15</td>\n","      <td>3</td>\n","      <td>0</td>\n","      <td>yes</td>\n","      <td>yes</td>\n","      <td>2</td>\n","      <td>15</td>\n","      <td>14</td>\n","      <td>15</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>GP</td>\n","      <td>F</td>\n","      <td>16</td>\n","      <td>2</td>\n","      <td>0</td>\n","      <td>yes</td>\n","      <td>no</td>\n","      <td>4</td>\n","      <td>6</td>\n","      <td>10</td>\n","      <td>10</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>390</th>\n","      <td>MS</td>\n","      <td>M</td>\n","      <td>20</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>yes</td>\n","      <td>no</td>\n","      <td>11</td>\n","      <td>9</td>\n","      <td>9</td>\n","      <td>9</td>\n","    </tr>\n","    <tr>\n","      <th>391</th>\n","      <td>MS</td>\n","      <td>M</td>\n","      <td>17</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>yes</td>\n","      <td>yes</td>\n","      <td>3</td>\n","      <td>14</td>\n","      <td>16</td>\n","      <td>16</td>\n","    </tr>\n","    <tr>\n","      <th>392</th>\n","      <td>MS</td>\n","      <td>M</td>\n","      <td>21</td>\n","      <td>1</td>\n","      <td>3</td>\n","      <td>yes</td>\n","      <td>no</td>\n","      <td>3</td>\n","      <td>10</td>\n","      <td>8</td>\n","      <td>7</td>\n","    </tr>\n","    <tr>\n","      <th>393</th>\n","      <td>MS</td>\n","      <td>M</td>\n","      <td>18</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>yes</td>\n","      <td>yes</td>\n","      <td>0</td>\n","      <td>11</td>\n","      <td>12</td>\n","      <td>10</td>\n","    </tr>\n","    <tr>\n","      <th>394</th>\n","      <td>MS</td>\n","      <td>M</td>\n","      <td>19</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>yes</td>\n","      <td>yes</td>\n","      <td>5</td>\n","      <td>8</td>\n","      <td>9</td>\n","      <td>9</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>395 rows × 11 columns</p>\n","</div>"],"text/plain":["    school sex  age  studytime  failures higher internet  absences  G1  G2  G3\n","0       GP   F   18          2         0    yes       no         6   5   6   6\n","1       GP   F   17          2         0    yes      yes         4   5   5   6\n","2       GP   F   15          2         3    yes      yes        10   7   8  10\n","3       GP   F   15          3         0    yes      yes         2  15  14  15\n","4       GP   F   16          2         0    yes       no         4   6  10  10\n","..     ...  ..  ...        ...       ...    ...      ...       ...  ..  ..  ..\n","390     MS   M   20          2         2    yes       no        11   9   9   9\n","391     MS   M   17          1         0    yes      yes         3  14  16  16\n","392     MS   M   21          1         3    yes       no         3  10   8   7\n","393     MS   M   18          1         0    yes      yes         0  11  12  10\n","394     MS   M   19          1         0    yes      yes         5   8   9   9\n","\n","[395 rows x 11 columns]"]},"metadata":{},"output_type":"display_data"}],"source":["df_delColunas = df.drop([\"health\",\"address\",\"famsize\",\"Pstatus\",\"Medu\",\"Fedu\",\"Mjob\",\"Fjob\",\"reason\",\"guardian\",\"traveltime\",\"schoolsup\",\"paid\",\"famsup\",\"activities\",\"nursery\",\"romantic\",\"famrel\",\"freetime\",\"goout\",\"Dalc\",\"Walc\"], axis=1)\n","display(df_delColunas)"]},{"cell_type":"code","execution_count":31,"metadata":{"execution":{"iopub.execute_input":"2023-10-18T16:19:01.059347Z","iopub.status.busy":"2023-10-18T16:19:01.058898Z","iopub.status.idle":"2023-10-18T16:19:01.081825Z","shell.execute_reply":"2023-10-18T16:19:01.080570Z","shell.execute_reply.started":"2023-10-18T16:19:01.059300Z"},"trusted":true},"outputs":[],"source":["df_delColunas['Approved'] = df_delColunas.apply(lambda row: 1 if (((row['G1'] + row['G2'] + row['G3']) / 3 > 10) and row['absences'] <= 10) else 0, axis=1)"]},{"cell_type":"code","execution_count":32,"metadata":{"execution":{"iopub.execute_input":"2023-10-18T16:19:01.083724Z","iopub.status.busy":"2023-10-18T16:19:01.083311Z","iopub.status.idle":"2023-10-18T16:19:01.093110Z","shell.execute_reply":"2023-10-18T16:19:01.091657Z","shell.execute_reply.started":"2023-10-18T16:19:01.083670Z"},"trusted":true},"outputs":[{"data":{"text/plain":["array([ 6,  4, 10,  2,  0, 16, 14,  7,  8, 25, 12, 54, 18, 26, 20, 56, 24,\n","       28,  5, 13, 15, 22,  3, 21,  1, 75, 30, 19,  9, 11, 38, 40, 23, 17])"]},"execution_count":32,"metadata":{},"output_type":"execute_result"}],"source":["df_delColunas['absences'].unique()"]},{"cell_type":"markdown","metadata":{},"source":["# Previsão Individual de G1, G2, G3 e Approved\n","## Regressão Linear"]},{"cell_type":"code","execution_count":33,"metadata":{"execution":{"iopub.execute_input":"2023-10-18T16:19:01.095457Z","iopub.status.busy":"2023-10-18T16:19:01.094875Z","iopub.status.idle":"2023-10-18T16:19:01.130652Z","shell.execute_reply":"2023-10-18T16:19:01.129428Z","shell.execute_reply.started":"2023-10-18T16:19:01.095424Z"},"trusted":true},"outputs":[],"source":["# Separate the predictor columns (X) and the target variables (y)\n","X_G1 = df_delColunas.drop(['G1', 'G2', 'G3', 'Approved'], axis=1)\n","X_G2 = df_delColunas.drop(['G2', 'G3', 'Approved'], axis=1)\n","X_G3 = df_delColunas.drop(['G3', 'Approved'], axis=1)\n","X_Approved = df_delColunas.drop('Approved', axis=1)\n","\n","y_G1 = df_delColunas['G1']\n","y_G2 = df_delColunas['G2']\n","y_G3 = df_delColunas['G3']\n","y_Approved = df_delColunas['Approved']\n","\n","# Perform one-hot encoding on the categorical features\n","X_G1_encoded = pd.get_dummies(X_G1)\n","X_G2_encoded = pd.get_dummies(X_G2)\n","X_G3_encoded = pd.get_dummies(X_G3)\n","X_Approved_encoded = pd.get_dummies(X_Approved)\n","\n","# Split the data into training and testing sets\n","X_G1_train, X_G1_test, y_G1_train, y_G1_test = train_test_split(X_G1_encoded, y_G1, test_size=0.2, random_state=42)\n","X_G2_train, X_G2_test, y_G2_train, y_G2_test = train_test_split(X_G2_encoded, y_G2, test_size=0.2, random_state=42)\n","X_G3_train, X_G3_test, y_G3_train, y_G3_test = train_test_split(X_G3_encoded, y_G3, test_size=0.2, random_state=42)\n","X_Approved_train, X_Approved_test, y_Approved_train, y_Approved_test = train_test_split(X_Approved_encoded, y_Approved, test_size=0.2, random_state=42)"]},{"cell_type":"code","execution_count":34,"metadata":{"execution":{"iopub.execute_input":"2023-10-18T16:19:01.132736Z","iopub.status.busy":"2023-10-18T16:19:01.132362Z","iopub.status.idle":"2023-10-18T16:19:01.159319Z","shell.execute_reply":"2023-10-18T16:19:01.158093Z","shell.execute_reply.started":"2023-10-18T16:19:01.132707Z"},"trusted":true},"outputs":[{"data":{"text/html":["<style>#sk-container-id-3 {color: black;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearRegression</label><div class=\"sk-toggleable__content\"><pre>LinearRegression()</pre></div></div></div></div></div>"],"text/plain":["LinearRegression()"]},"execution_count":34,"metadata":{},"output_type":"execute_result"}],"source":["# Create and train the linear regression model for G1\n","regressor_G1 = LinearRegression()\n","regressor_G1.fit(X_G1_train, y_G1_train)\n","\n","# Create and train the linear regression model for G2\n","regressor_G2 = LinearRegression()\n","regressor_G2.fit(X_G2_train, y_G2_train)\n","\n","# Create and train the linear regression model for G3\n","regressor_G3 = LinearRegression()\n","regressor_G3.fit(X_G3_train, y_G3_train)\n","\n","# Create and train the linear regression model for Approved\n","regressor_Approved = LinearRegression()\n","regressor_Approved.fit(X_Approved_train, y_Approved_train)"]},{"cell_type":"code","execution_count":35,"metadata":{"execution":{"iopub.execute_input":"2023-10-18T16:19:01.162582Z","iopub.status.busy":"2023-10-18T16:19:01.162236Z","iopub.status.idle":"2023-10-18T16:19:01.180242Z","shell.execute_reply":"2023-10-18T16:19:01.178921Z","shell.execute_reply.started":"2023-10-18T16:19:01.162557Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Mean Absolute Error (G1): 2.9942021883275505\n","Mean Absolute Error (G2): 1.1598800728672158\n","Mean Absolute Error (G3): 1.346370714289203\n","Mean Absolute Error (Approved): 0.23050038977116102\n"]}],"source":["# Make predictions for G1, G2, and G3\n","y_G1_pred = regressor_G1.predict(X_G1_test)\n","y_G2_pred = regressor_G2.predict(X_G2_test)\n","y_G3_pred = regressor_G3.predict(X_G3_test)\n","y_Approved_pred = regressor_Approved.predict(X_Approved_test)\n","\n","# Evaluate the linear regression model using Mean Absolute Error (MAE)\n","mae_G1 = mean_absolute_error(y_G1_test, y_G1_pred)\n","mae_G2 = mean_absolute_error(y_G2_test, y_G2_pred)\n","mae_G3 = mean_absolute_error(y_G3_test, y_G3_pred)\n","mae_Approved = mean_absolute_error(y_Approved_test, y_Approved_pred)\n","\n","# # Print the predictions and the actual values side by side for G1\n","# print(\"Prediction for G1\")\n","# for pred, real in zip(y_G1_pred, y_G1_test):\n","#     print(f\"Predicted: {pred:.2f} - Actual: {real:.2f} => Diff: {(pred-real):.2f}\")\n","\n","# # Print the predictions and the actual values side by side for G2\n","# print(\"\\nPrediction for G2\")\n","# for pred, real in zip(y_G2_pred, y_G2_test):\n","#     print(f\"Predicted: {pred:.2f} - Actual: {real:.2f} => Diff: {(pred-real):.2f}\")\n","\n","# # Print the predictions and the actual values side by side for G3\n","# print(\"\\nPrediction for G3\")\n","# for pred, real in zip(y_G3_pred, y_G3_test):\n","#     print(f\"Predicted: {pred:.2f} - Actual: {real:.2f} => Diff: {(pred-real):.2f}\")\n","    \n","# # Print the predictions and the actual values side by side for Approved\n","# print(\"\\nPrediction for Approved\")\n","# for pred, real in zip(y_Approved_pred, y_Approved_test):\n","#     print(f\"Predicted: {pred:.2f} - Actual: {real:.2f} => Diff: {(pred-real):.2f}\")\n","\n","# Print the Mean Absolute Error (MAE) for G1, G2, and G3\n","print(\"Mean Absolute Error (G1):\", mae_G1)\n","print(\"Mean Absolute Error (G2):\", mae_G2)\n","print(\"Mean Absolute Error (G3):\", mae_G3)\n","print(\"Mean Absolute Error (Approved):\", mae_Approved)"]},{"cell_type":"markdown","metadata":{},"source":["## Redes Neurais"]},{"cell_type":"code","execution_count":36,"metadata":{"execution":{"iopub.execute_input":"2023-10-18T16:19:01.182952Z","iopub.status.busy":"2023-10-18T16:19:01.181594Z","iopub.status.idle":"2023-10-18T16:19:01.263054Z","shell.execute_reply":"2023-10-18T16:19:01.262090Z","shell.execute_reply.started":"2023-10-18T16:19:01.182889Z"},"trusted":true},"outputs":[],"source":["import pandas as pd\n","import tensorflow as tf\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import mean_absolute_error\n","\n","# Load the DataFrame\n","df_delColunas = pd.read_csv(path)\n","\n","df_delColunas['Approved'] = df_delColunas.apply(lambda row: 1 if (((row['G1'] + row['G2'] + row['G3']) / 3 > 10) and row['absences'] <= 10) else 0, axis=1)\n","\n","# Separate the predictor columns (X) and the target variables (y)\n","X_G1 = df_delColunas.drop(['G1', 'G2', 'G3', 'Approved'], axis=1)\n","X_G2 = df_delColunas.drop(['G2', 'G3', 'Approved'], axis=1)\n","X_G3 = df_delColunas.drop(['G3', 'Approved'], axis=1)\n","X_Approved = df_delColunas.drop('Approved', axis=1)\n","\n","y_G1 = df_delColunas['G1']\n","y_G2 = df_delColunas['G2']\n","y_G3 = df_delColunas['G3']\n","y_Approved = df_delColunas['Approved']\n","\n","# Perform one-hot encoding on the categorical features\n","X_G1_encoded = pd.get_dummies(X_G1)\n","X_G2_encoded = pd.get_dummies(X_G2)\n","X_G3_encoded = pd.get_dummies(X_G3)\n","X_Approved_encoded = pd.get_dummies(X_Approved)\n","\n","# Split the data into training and testing sets\n","X_G1_train, X_G1_test, y_G1_train, y_G1_test = train_test_split(X_G1_encoded, y_G1, test_size=0.2, random_state=42)\n","X_G2_train, X_G2_test, y_G2_train, y_G2_test = train_test_split(X_G2_encoded, y_G2, test_size=0.2, random_state=42)\n","X_G3_train, X_G3_test, y_G3_train, y_G3_test = train_test_split(X_G3_encoded, y_G3, test_size=0.2, random_state=42)\n","X_Approved_train, X_Approved_test, y_Approved_train, y_Approved_test = train_test_split(X_Approved_encoded, y_Approved, test_size=0.2, random_state=42)"]},{"cell_type":"code","execution_count":40,"metadata":{"execution":{"iopub.execute_input":"2023-10-18T16:19:01.264724Z","iopub.status.busy":"2023-10-18T16:19:01.264445Z","iopub.status.idle":"2023-10-18T16:19:12.884910Z","shell.execute_reply":"2023-10-18T16:19:12.883557Z","shell.execute_reply.started":"2023-10-18T16:19:01.264700Z"},"trusted":true},"outputs":[{"ename":"ValueError","evalue":"Failed to convert a NumPy array to a Tensor (Unsupported object type int).","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[1;32m/home/fause/06_AcompanhamentoEnsinoMedio/src/ML/student-perfomance .ipynb Cell 13\u001b[0m line \u001b[0;36m1\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/fause/06_AcompanhamentoEnsinoMedio/src/ML/student-perfomance%20.ipynb#X15sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m model_G1 \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mkeras\u001b[39m.\u001b[39mSequential([\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/fause/06_AcompanhamentoEnsinoMedio/src/ML/student-perfomance%20.ipynb#X15sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m     tf\u001b[39m.\u001b[39mkeras\u001b[39m.\u001b[39mlayers\u001b[39m.\u001b[39mDense(\u001b[39m30\u001b[39m, activation\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mrelu\u001b[39m\u001b[39m'\u001b[39m, input_shape\u001b[39m=\u001b[39m(X_G1_train\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m],)),\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/fause/06_AcompanhamentoEnsinoMedio/src/ML/student-perfomance%20.ipynb#X15sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m     tf\u001b[39m.\u001b[39mkeras\u001b[39m.\u001b[39mlayers\u001b[39m.\u001b[39mDense(\u001b[39m60\u001b[39m, activation\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mrelu\u001b[39m\u001b[39m'\u001b[39m),\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/fause/06_AcompanhamentoEnsinoMedio/src/ML/student-perfomance%20.ipynb#X15sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m     tf\u001b[39m.\u001b[39mkeras\u001b[39m.\u001b[39mlayers\u001b[39m.\u001b[39mDense(\u001b[39m20\u001b[39m, activation\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mrelu\u001b[39m\u001b[39m'\u001b[39m),\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/fause/06_AcompanhamentoEnsinoMedio/src/ML/student-perfomance%20.ipynb#X15sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m     tf\u001b[39m.\u001b[39mkeras\u001b[39m.\u001b[39mlayers\u001b[39m.\u001b[39mDense(\u001b[39m1\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/fause/06_AcompanhamentoEnsinoMedio/src/ML/student-perfomance%20.ipynb#X15sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m ])\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/fause/06_AcompanhamentoEnsinoMedio/src/ML/student-perfomance%20.ipynb#X15sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m model_G1\u001b[39m.\u001b[39mcompile(optimizer\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39madam\u001b[39m\u001b[39m'\u001b[39m, loss\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mmean_squared_error\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/fause/06_AcompanhamentoEnsinoMedio/src/ML/student-perfomance%20.ipynb#X15sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m model_G1\u001b[39m.\u001b[39;49mfit(X_G1_train, y_G1_train, epochs\u001b[39m=\u001b[39;49m\u001b[39m100\u001b[39;49m, batch_size\u001b[39m=\u001b[39;49m\u001b[39m32\u001b[39;49m, verbose\u001b[39m=\u001b[39;49m\u001b[39m0\u001b[39;49m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/fause/06_AcompanhamentoEnsinoMedio/src/ML/student-perfomance%20.ipynb#X15sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m \u001b[39m# Create and train the neural network model for G2\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/fause/06_AcompanhamentoEnsinoMedio/src/ML/student-perfomance%20.ipynb#X15sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m model_G2 \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mkeras\u001b[39m.\u001b[39mSequential([\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/fause/06_AcompanhamentoEnsinoMedio/src/ML/student-perfomance%20.ipynb#X15sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m     tf\u001b[39m.\u001b[39mkeras\u001b[39m.\u001b[39mlayers\u001b[39m.\u001b[39mDense(\u001b[39m30\u001b[39m, activation\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mrelu\u001b[39m\u001b[39m'\u001b[39m, input_shape\u001b[39m=\u001b[39m(X_G2_train\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m],)),\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/fause/06_AcompanhamentoEnsinoMedio/src/ML/student-perfomance%20.ipynb#X15sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m     tf\u001b[39m.\u001b[39mkeras\u001b[39m.\u001b[39mlayers\u001b[39m.\u001b[39mDense(\u001b[39m60\u001b[39m, activation\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mrelu\u001b[39m\u001b[39m'\u001b[39m),\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/fause/06_AcompanhamentoEnsinoMedio/src/ML/student-perfomance%20.ipynb#X15sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m     tf\u001b[39m.\u001b[39mkeras\u001b[39m.\u001b[39mlayers\u001b[39m.\u001b[39mDense(\u001b[39m20\u001b[39m, activation\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mrelu\u001b[39m\u001b[39m'\u001b[39m),\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/fause/06_AcompanhamentoEnsinoMedio/src/ML/student-perfomance%20.ipynb#X15sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m     tf\u001b[39m.\u001b[39mkeras\u001b[39m.\u001b[39mlayers\u001b[39m.\u001b[39mDense(\u001b[39m1\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/fause/06_AcompanhamentoEnsinoMedio/src/ML/student-perfomance%20.ipynb#X15sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m ])\n","File \u001b[0;32m~/.local/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n","File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/framework/constant_op.py:102\u001b[0m, in \u001b[0;36mconvert_to_eager_tensor\u001b[0;34m(value, ctx, dtype)\u001b[0m\n\u001b[1;32m    100\u001b[0m     dtype \u001b[39m=\u001b[39m dtypes\u001b[39m.\u001b[39mas_dtype(dtype)\u001b[39m.\u001b[39mas_datatype_enum\n\u001b[1;32m    101\u001b[0m ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[0;32m--> 102\u001b[0m \u001b[39mreturn\u001b[39;00m ops\u001b[39m.\u001b[39;49mEagerTensor(value, ctx\u001b[39m.\u001b[39;49mdevice_name, dtype)\n","\u001b[0;31mValueError\u001b[0m: Failed to convert a NumPy array to a Tensor (Unsupported object type int)."]}],"source":["# Create and train the neural network model for G1\n","model_G1 = tf.keras.Sequential([\n","    tf.keras.layers.Dense(30, activation='relu', input_shape=(X_G1_train.shape[1],)),\n","    tf.keras.layers.Dense(60, activation='relu'),\n","    tf.keras.layers.Dense(20, activation='relu'),\n","    tf.keras.layers.Dense(1)\n","])\n","\n","model_G1.compile(optimizer='adam', loss='mean_squared_error')\n","\n","model_G1.fit(X_G1_train, y_G1_train, epochs=100, batch_size=32, verbose=0)\n","\n","# Create and train the neural network model for G2\n","model_G2 = tf.keras.Sequential([\n","    tf.keras.layers.Dense(30, activation='relu', input_shape=(X_G2_train.shape[1],)),\n","    tf.keras.layers.Dense(60, activation='relu'),\n","    tf.keras.layers.Dense(20, activation='relu'),\n","    tf.keras.layers.Dense(1)\n","])\n","\n","model_G2.compile(optimizer='adam', loss='mean_squared_error')\n","\n","model_G2.fit(X_G2_train, y_G2_train, epochs=100, batch_size=32, verbose=0)\n","\n","# Create and train the neural network model for G3\n","model_G3 = tf.keras.Sequential([\n","    tf.keras.layers.Dense(30, activation='relu', input_shape=(X_G3_train.shape[1],)),\n","    tf.keras.layers.Dense(60, activation='relu'),\n","    tf.keras.layers.Dense(20, activation='relu'),\n","    tf.keras.layers.Dense(1)\n","])\n","\n","model_G3.compile(optimizer='adam', loss='mean_squared_error')\n","\n","model_G3.fit(X_G3_train, y_G3_train,epochs=100, batch_size=32, verbose=0)\n","\n","# Create and train the neural network model for Approved\n","model_Approved = tf.keras.Sequential([\n","    tf.keras.layers.Dense(30, activation='relu', input_shape=(X_Approved_train.shape[1],)),\n","    tf.keras.layers.Dense(15, activation='relu'),\n","    tf.keras.layers.Dense(1, activation='sigmoid')\n","])\n","\n","model_Approved.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n","\n","model_Approved.fit(X_Approved_train, y_Approved_train, epochs=100, batch_size=32, verbose=0)"]},{"cell_type":"code","execution_count":38,"metadata":{"execution":{"iopub.execute_input":"2023-10-18T16:19:12.888346Z","iopub.status.busy":"2023-10-18T16:19:12.887913Z","iopub.status.idle":"2023-10-18T16:19:13.386254Z","shell.execute_reply":"2023-10-18T16:19:13.385236Z","shell.execute_reply.started":"2023-10-18T16:19:12.888317Z"},"trusted":true},"outputs":[{"ename":"ValueError","evalue":"Failed to convert a NumPy array to a Tensor (Unsupported object type int).","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[1;32m/home/fause/06_AcompanhamentoEnsinoMedio/src/ML/student-perfomance .ipynb Cell 14\u001b[0m line \u001b[0;36m2\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/fause/06_AcompanhamentoEnsinoMedio/src/ML/student-perfomance%20.ipynb#X16sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# Make predictions for G1, G2, G3, and Approved\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/fause/06_AcompanhamentoEnsinoMedio/src/ML/student-perfomance%20.ipynb#X16sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m y_G1_pred \u001b[39m=\u001b[39m model_G1\u001b[39m.\u001b[39;49mpredict(X_G1_test)\u001b[39m.\u001b[39mflatten()\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/fause/06_AcompanhamentoEnsinoMedio/src/ML/student-perfomance%20.ipynb#X16sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m y_G2_pred \u001b[39m=\u001b[39m model_G2\u001b[39m.\u001b[39mpredict(X_G2_test)\u001b[39m.\u001b[39mflatten()\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/fause/06_AcompanhamentoEnsinoMedio/src/ML/student-perfomance%20.ipynb#X16sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m y_G3_pred \u001b[39m=\u001b[39m model_G3\u001b[39m.\u001b[39mpredict(X_G3_test)\u001b[39m.\u001b[39mflatten()\n","File \u001b[0;32m~/.local/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n","File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/framework/constant_op.py:102\u001b[0m, in \u001b[0;36mconvert_to_eager_tensor\u001b[0;34m(value, ctx, dtype)\u001b[0m\n\u001b[1;32m    100\u001b[0m     dtype \u001b[39m=\u001b[39m dtypes\u001b[39m.\u001b[39mas_dtype(dtype)\u001b[39m.\u001b[39mas_datatype_enum\n\u001b[1;32m    101\u001b[0m ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[0;32m--> 102\u001b[0m \u001b[39mreturn\u001b[39;00m ops\u001b[39m.\u001b[39;49mEagerTensor(value, ctx\u001b[39m.\u001b[39;49mdevice_name, dtype)\n","\u001b[0;31mValueError\u001b[0m: Failed to convert a NumPy array to a Tensor (Unsupported object type int)."]}],"source":["# Make predictions for G1, G2, G3, and Approved\n","y_G1_pred = model_G1.predict(X_G1_test).flatten()\n","y_G2_pred = model_G2.predict(X_G2_test).flatten()\n","y_G3_pred = model_G3.predict(X_G3_test).flatten()\n","y_Approved_pred = model_Approved.predict(X_Approved_test).flatten()\n","\n","# Calculate and print the Mean Absolute Error (MAE) for G1, G2, G3, and Approved\n","mae_G1 = mean_absolute_error(y_G1_test, y_G1_pred)\n","mae_G2 = mean_absolute_error(y_G2_test, y_G2_pred)\n","mae_G3 = mean_absolute_error(y_G3_test, y_G3_pred)\n","mae_Approved = mean_absolute_error(y_Approved_test, y_Approved_pred)\n","\n","print(\"Mean Absolute Error (G1):\", mae_G1)\n","print(\"Mean Absolute Error (G2):\", mae_G2)\n","print(\"Mean Absolute Error (G3):\", mae_G3)\n","print(\"Mean Absolute Error (Approved):\", mae_Approved)"]},{"cell_type":"markdown","metadata":{},"source":["# Previsão das Notas G1, G2, G3 e Approved em cima das próprias previsões"]},{"cell_type":"code","execution_count":39,"metadata":{"execution":{"iopub.execute_input":"2023-10-18T16:19:13.388212Z","iopub.status.busy":"2023-10-18T16:19:13.387795Z","iopub.status.idle":"2023-10-18T16:19:27.226531Z","shell.execute_reply":"2023-10-18T16:19:27.225375Z","shell.execute_reply.started":"2023-10-18T16:19:13.388175Z"},"trusted":true},"outputs":[{"ename":"ValueError","evalue":"Failed to convert a NumPy array to a Tensor (Unsupported object type int).","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[1;32m/home/fause/06_AcompanhamentoEnsinoMedio/src/ML/student-perfomance .ipynb Cell 16\u001b[0m line \u001b[0;36m4\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/fause/06_AcompanhamentoEnsinoMedio/src/ML/student-perfomance%20.ipynb#X21sZmlsZQ%3D%3D?line=34'>35</a>\u001b[0m model_G1 \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mkeras\u001b[39m.\u001b[39mSequential([\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/fause/06_AcompanhamentoEnsinoMedio/src/ML/student-perfomance%20.ipynb#X21sZmlsZQ%3D%3D?line=35'>36</a>\u001b[0m     tf\u001b[39m.\u001b[39mkeras\u001b[39m.\u001b[39mlayers\u001b[39m.\u001b[39mDense(\u001b[39m56\u001b[39m, activation\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mrelu\u001b[39m\u001b[39m'\u001b[39m, input_shape\u001b[39m=\u001b[39m(X_G1_train\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m],)),\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/fause/06_AcompanhamentoEnsinoMedio/src/ML/student-perfomance%20.ipynb#X21sZmlsZQ%3D%3D?line=36'>37</a>\u001b[0m     tf\u001b[39m.\u001b[39mkeras\u001b[39m.\u001b[39mlayers\u001b[39m.\u001b[39mDense(\u001b[39m42\u001b[39m, activation\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mrelu\u001b[39m\u001b[39m'\u001b[39m),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/fause/06_AcompanhamentoEnsinoMedio/src/ML/student-perfomance%20.ipynb#X21sZmlsZQ%3D%3D?line=39'>40</a>\u001b[0m     tf\u001b[39m.\u001b[39mkeras\u001b[39m.\u001b[39mlayers\u001b[39m.\u001b[39mDense(\u001b[39m1\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/fause/06_AcompanhamentoEnsinoMedio/src/ML/student-perfomance%20.ipynb#X21sZmlsZQ%3D%3D?line=40'>41</a>\u001b[0m ])\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/fause/06_AcompanhamentoEnsinoMedio/src/ML/student-perfomance%20.ipynb#X21sZmlsZQ%3D%3D?line=41'>42</a>\u001b[0m model_G1\u001b[39m.\u001b[39mcompile(optimizer\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39madam\u001b[39m\u001b[39m'\u001b[39m, loss\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mmean_squared_error\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/fause/06_AcompanhamentoEnsinoMedio/src/ML/student-perfomance%20.ipynb#X21sZmlsZQ%3D%3D?line=42'>43</a>\u001b[0m model_G1\u001b[39m.\u001b[39;49mfit(X_G1_train, y_G1_train, epochs\u001b[39m=\u001b[39;49m\u001b[39m200\u001b[39;49m, batch_size\u001b[39m=\u001b[39;49m\u001b[39m28\u001b[39;49m, verbose\u001b[39m=\u001b[39;49m\u001b[39m0\u001b[39;49m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/fause/06_AcompanhamentoEnsinoMedio/src/ML/student-perfomance%20.ipynb#X21sZmlsZQ%3D%3D?line=43'>44</a>\u001b[0m \u001b[39m# Predict G1 for the test set\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/fause/06_AcompanhamentoEnsinoMedio/src/ML/student-perfomance%20.ipynb#X21sZmlsZQ%3D%3D?line=44'>45</a>\u001b[0m y_G1_pred \u001b[39m=\u001b[39m model_G1\u001b[39m.\u001b[39mpredict(X_G1_test)\n","File \u001b[0;32m~/.local/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n","File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/framework/constant_op.py:102\u001b[0m, in \u001b[0;36mconvert_to_eager_tensor\u001b[0;34m(value, ctx, dtype)\u001b[0m\n\u001b[1;32m    100\u001b[0m     dtype \u001b[39m=\u001b[39m dtypes\u001b[39m.\u001b[39mas_dtype(dtype)\u001b[39m.\u001b[39mas_datatype_enum\n\u001b[1;32m    101\u001b[0m ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[0;32m--> 102\u001b[0m \u001b[39mreturn\u001b[39;00m ops\u001b[39m.\u001b[39;49mEagerTensor(value, ctx\u001b[39m.\u001b[39;49mdevice_name, dtype)\n","\u001b[0;31mValueError\u001b[0m: Failed to convert a NumPy array to a Tensor (Unsupported object type int)."]}],"source":["import pandas as pd\n","import tensorflow as tf\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import mean_absolute_error\n","\n","# Load the DataFrame\n","df_delColunas = pd.read_csv(path)\n","\n","df_delColunas['Approved'] = df_delColunas.apply(lambda row: 1 if (((row['G1'] + row['G2'] + row['G3']) / 3 > 10) and row['absences'] <= 10) else 0, axis=1)\n","\n","# Separate the predictor columns (X) and the target variables (y)\n","X_G1 = df_delColunas.drop(['G1', 'G2', 'G3', 'Approved'], axis=1)\n","X_G2 = df_delColunas.drop(['G2', 'G3', 'Approved'], axis=1)\n","X_G3 = df_delColunas.drop(['G3', 'Approved'], axis=1)\n","X_Approved = df_delColunas.drop('Approved', axis=1)\n","\n","y_G1 = df_delColunas['G1']\n","y_G2 = df_delColunas['G2']\n","y_G3 = df_delColunas['G3']\n","y_Approved = df_delColunas['Approved']\n","\n","# Perform one-hot encoding on the categorical features\n","X_G1_encoded = pd.get_dummies(X_G1)\n","X_G2_encoded = pd.get_dummies(X_G2)\n","X_G3_encoded = pd.get_dummies(X_G3)\n","X_Approved_encoded = pd.get_dummies(X_Approved)\n","\n","# Split the data into training and testing sets\n","X_G1_train, X_G1_test, y_G1_train, y_G1_test = train_test_split(X_G1_encoded, y_G1, test_size=0.2, random_state=42)\n","X_G2_train, X_G2_test, y_G2_train, y_G2_test = train_test_split(X_G2_encoded, y_G2, test_size=0.2, random_state=42)\n","X_G3_train, X_G3_test, y_G3_train, y_G3_test = train_test_split(X_G3_encoded, y_G3, test_size=0.2, random_state=42)\n","X_Approved_train, X_Approved_test, y_Approved_train, y_Approved_test = train_test_split(X_Approved_encoded, y_Approved, test_size=0.2, random_state=42)\n","\n","# Create and train the neural network model for G1\n","model_G1 = tf.keras.Sequential([\n","    tf.keras.layers.Dense(56, activation='relu', input_shape=(X_G1_train.shape[1],)),\n","    tf.keras.layers.Dense(42, activation='relu'),\n","    tf.keras.layers.Dense(36, activation='relu'),\n","    tf.keras.layers.Dense(20, activation='relu'),\n","    tf.keras.layers.Dense(1)\n","])\n","model_G1.compile(optimizer='adam', loss='mean_squared_error')\n","model_G1.fit(X_G1_train, y_G1_train, epochs=200, batch_size=28, verbose=0)\n","# Predict G1 for the test set\n","y_G1_pred = model_G1.predict(X_G1_test)\n","\n","# Create a new DataFrame for X_G2 with the predicted G1 values\n","X_G2_pred = X_G2_test.copy()\n","X_G2_pred['G1'] = y_G1_pred\n","# Create and train the neural network model for G2\n","model_G2 = tf.keras.Sequential([\n","    tf.keras.layers.Dense(57, activation='relu', input_shape=(X_G2_pred.shape[1],)),\n","    tf.keras.layers.Dense(26, activation='relu'),\n","    tf.keras.layers.Dense(1)\n","])\n","model_G2.compile(optimizer='adam', loss='mean_squared_error')\n","model_G2.fit(X_G2_pred, y_G2_test, epochs=300, batch_size=32, verbose=0)\n","# Predict G2 for the test set\n","y_G2_pred = model_G2.predict(X_G2_test)\n","\n","# Create a new DataFrame for X_G3 with the predicted G1 and G2 values\n","X_G3_pred = X_G3_test.copy()\n","X_G3_pred['G1'] = y_G1_pred\n","X_G3_pred['G2'] = y_G2_pred\n","# Create and train the neural network model for G3\n","model_G3 = tf.keras.Sequential([\n","    tf.keras.layers.Dense(58, activation='relu', input_shape=(X_G3_pred.shape[1],)),\n","    tf.keras.layers.Dense(29, activation='relu'),\n","    tf.keras.layers.Dense(1)\n","])\n","model_G3.compile(optimizer='adam', loss='mean_squared_error')\n","model_G3.fit(X_G3_pred, y_G3_test, epochs=300, batch_size=32, verbose=0)\n","# Predict G3 for the test set\n","y_G3_pred = model_G3.predict(X_G3_test)\n","\n","# Create a new DataFrame for X_Approved with the predicted G1, G2, and G3 values\n","X_Approved_pred = X_Approved_test.copy()\n","X_Approved_pred['G1'] = y_G1_pred\n","X_Approved_pred['G2'] = y_G2_pred\n","X_Approved_pred['G3'] = y_G3_pred\n","# Create and train the neural network model for Approved\n","model_Approved = tf.keras.Sequential([\n","    tf.keras.layers.Dense(59, activation='relu', input_shape=(X_Approved_pred.shape[1],)),\n","    tf.keras.layers.Dense(34, activation='relu'),\n","    tf.keras.layers.Dense(1, activation='sigmoid')\n","])\n","model_Approved.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n","model_Approved.fit(X_Approved_pred, y_Approved_test, epochs=35, batch_size=32, verbose=0)\n","\n","# Make predictions for G1, G2, G3, and Approved\n","y_G1_pred = model_G1.predict(X_G1_test).flatten()\n","y_G2_pred = model_G2.predict(X_G2_test).flatten()\n","y_G3_pred = model_G3.predict(X_G3_test).flatten()\n","y_Approved_pred = model_Approved.predict(X_Approved_test).flatten()\n","\n","# Calculate and print the Mean Absolute Error (MAE) for G1, G2, G3, and Approved\n","mae_G1 = mean_absolute_error(y_G1_test, y_G1_pred)\n","mae_G2 = mean_absolute_error(y_G2_test, y_G2_pred)\n","mae_G3 = mean_absolute_error(y_G3_test, y_G3_pred)\n","mae_Approved = mean_absolute_error(y_Approved_test, y_Approved_pred)\n","\n","print(\"Mean Absolute Error (G1):\", mae_G1)\n","print(\"Mean Absolute Error (G2):\", mae_G2)\n","print(\"Mean Absolute Error (G3):\", mae_G3)\n","print(\"Mean Absolute Error (Approved):\", mae_Approved)"]},{"cell_type":"markdown","metadata":{},"source":["# Testando previsões em estudante aleatório"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-18T16:19:27.228328Z","iopub.status.busy":"2023-10-18T16:19:27.227995Z","iopub.status.idle":"2023-10-18T16:19:27.502927Z","shell.execute_reply":"2023-10-18T16:19:27.501609Z","shell.execute_reply.started":"2023-10-18T16:19:27.228304Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["1/1 [==============================] - 0s 23ms/step\n","1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 26ms/step\n","\n","G1\n","Predicted: 8.34 - Actual: 11.00\n","\n","G2\n","Predicted: 11.52 - Actual: 10.00\n","\n","G3\n","Predicted: 9.47 - Actual: 10.00\n","\n","Approved\n","Predicted: 1 - Actual: 1\n"]}],"source":["import numpy as np\n","\n","# Escolha o índice do estudante aleatório do conjunto de teste\n","random_student_index = 45\n","\n","# Obtenha a linha correspondente aos dados desse estudante no conjunto de teste\n","X_G1_test_student = np.array(X_G1_test.iloc[random_student_index]).reshape(1, -1)\n","X_G2_test_student = np.array(X_G2_test.iloc[random_student_index]).reshape(1, -1)\n","X_G3_test_student = np.array(X_G3_test.iloc[random_student_index]).reshape(1, -1)\n","X_Approved_test_student = np.array(X_Approved_test.iloc[random_student_index]).reshape(1, -1)\n","\n","# Faça a previsão para G1, G2, G3 e Approved para esse estudante\n","y_G1_pred_student = model_G1.predict(X_G1_test_student)[0][0]\n","y_G2_pred_student = model_G2.predict(X_G2_test_student)[0][0]\n","y_G3_pred_student = model_G3.predict(X_G3_test_student)[0][0]\n","y_Approved_pred_student = model_Approved.predict(X_Approved_test_student)[0][0]\n","\n","# Obtenha os valores reais para G1, G2, G3 e Approved para esse estudante\n","y_G1_actual_student = y_G1_test.iloc[random_student_index]\n","y_G2_actual_student = y_G2_test.iloc[random_student_index]\n","y_G3_actual_student = y_G3_test.iloc[random_student_index]\n","y_Approved_actual_student = y_Approved_test.iloc[random_student_index]\n","\n","# Imprima as previsões e os valores reais para G1, G2, G3 e Approved do estudante selecionado\n","print(\"\\nG1\")\n","print(f\"Predicted: {y_G1_pred_student:.2f} - Actual: {y_G1_actual_student:.2f}\")\n","\n","print(\"\\nG2\")\n","print(f\"Predicted: {y_G2_pred_student:.2f} - Actual: {y_G2_actual_student:.2f}\")\n","\n","print(\"\\nG3\")\n","print(f\"Predicted: {y_G3_pred_student:.2f} - Actual: {y_G3_actual_student:.2f}\")\n","\n","print(\"\\nApproved\")\n","print(f\"Predicted: {y_Approved_pred_student:.0f} - Actual: {y_Approved_actual_student}\")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.10"}},"nbformat":4,"nbformat_minor":4}
